{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24b206f-d040-430a-88b8-4ea92405403b",
   "metadata": {},
   "source": [
    "MiniSOM Tutorial for 2-D Atmospheric Data and Example Using Mean Sea Level Pressure Data \n",
    "\n",
    "Bsckground on Self Organizing Maps (SOMs)\n",
    "Self-organizing Maps, SOMs, are a form of unsupervised learning that utilizes a competitive neural network to cluster alike data. SOMs are like the clustering technique used in K-means. SOMs take multidimensional data and reduce it to a two-dimensional array that can be easily visualized. Patterns that share similar characteristics are grouped adjacent to one another; whereas patterns that share minimal similarities are grouped on opposing sides of the SOM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd96f4-fbd5-4699-b2a7-294c37979149",
   "metadata": {},
   "source": [
    "MiniSOM Tutorial: This notebook will generate the SOMs themselves, plot the frequencies, sammon maps, and the SOM anomaly plots. This is Step #2 in the MiniSOM Tutorial for 2-D Atmospheric Data and Example Using Mean Sea Level Pressure Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605486f0-99b1-4b99-b7ef-ab4fac81992c",
   "metadata": {},
   "source": [
    "Imports for the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5bccd7-7c41-41b0-8161-f357e7ef2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import minisom\n",
    "import pickle\n",
    "from minisom import asymptotic_decay\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from cartopy.util import add_cyclic_point\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177e50b-55b0-455e-943e-48f967c7b139",
   "metadata": {},
   "source": [
    "Functions Used in the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d6c8b-9987-4097-b879-8491a0f6a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions Used in the Code\n",
    "def getList(dict):\n",
    "    list = []\n",
    "    for key in winmap.keys():\n",
    "        list.append(key)\n",
    "        \n",
    "    return list\n",
    "def sammon(x, n, display = 2, inputdist = 'raw', maxhalves = 20, maxiter = 500, tolfun = 1e-9, init = 'default'):\n",
    "\n",
    "    import numpy as np \n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    \"\"\"Perform Sammon mapping on dataset x\n",
    "    y = sammon(x) applies the Sammon nonlinear mapping procedure on\n",
    "    multivariate data x, where each row represents a pattern and each column\n",
    "    represents a feature.  On completion, y contains the corresponding\n",
    "    co-ordinates of each point on the map.  By default, a two-dimensional\n",
    "    map is created.  Note if x contains any duplicated rows, SAMMON will\n",
    "    fail (ungracefully). \n",
    "    [y,E] = sammon(x) also returns the value of the cost function in E (i.e.\n",
    "    the stress of the mapping).\n",
    "    An N-dimensional output map is generated by y = sammon(x,n) .\n",
    "    A set of optimisation options can be specified using optional\n",
    "    arguments, y = sammon(x,n,[OPTS]):\n",
    "       maxiter        - maximum number of iterations\n",
    "       tolfun         - relative tolerance on objective function\n",
    "       maxhalves      - maximum number of step halvings\n",
    "       input          - {'raw','distance'} if set to 'distance', X is \n",
    "                        interpreted as a matrix of pairwise distances.\n",
    "       display        - 0 to 2. 0 least verbose, 2 max verbose.\n",
    "       init           - {'pca', 'cmdscale', random', 'default'}\n",
    "                        default is 'pca' if input is 'raw', \n",
    "                        'msdcale' if input is 'distance'\n",
    "    The default options are retrieved by calling sammon(x) with no\n",
    "    parameters.\n",
    "    File        : sammon.py\n",
    "    Date        : 18 April 2014\n",
    "    Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)\n",
    "                : Ported from MATLAB implementation by \n",
    "                  Gavin C. Cawley and Nicola L. C. Talbot\n",
    "    Description : Simple python implementation of Sammon's non-linear\n",
    "                  mapping algorithm [1].\n",
    "    References  : [1] Sammon, John W. Jr., \"A Nonlinear Mapping for Data\n",
    "                  Structure Analysis\", IEEE Transactions on Computers,\n",
    "                  vol. C-18, no. 5, pp 401-409, May 1969.\n",
    "    Copyright   : (c) Dr Gavin C. Cawley, November 2007.\n",
    "    This program is free software; you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation; either version 2 of the License, or\n",
    "    (at your option) any later version.\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program; if not, write to the Free Software\n",
    "    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n",
    "    \"\"\"\n",
    "\n",
    "    # Create distance matrix unless given by parameters\n",
    "    if inputdist == 'distance':\n",
    "        D = x\n",
    "        if init == 'default':\n",
    "            init = 'cmdscale'\n",
    "    else:\n",
    "        D = cdist(x, x)\n",
    "        if init == 'default':\n",
    "            init = 'pca'\n",
    "\n",
    "    if inputdist == 'distance' and init == 'pca':\n",
    "        raise ValueError(\"Cannot use init == 'pca' when inputdist == 'distance'\")\n",
    "\n",
    "    if np.count_nonzero(np.diagonal(D)) > 0:\n",
    "        raise ValueError(\"The diagonal of the dissimilarity matrix must be zero\")\n",
    "\n",
    "    # Remaining initialisation\n",
    "    N = x.shape[0]\n",
    "    scale = 0.5 / D.sum()\n",
    "    D = D + np.eye(N)     \n",
    "\n",
    "    if np.count_nonzero(D<=0) > 0:\n",
    "        raise ValueError(\"Off-diagonal dissimilarities must be strictly positive\")   \n",
    "\n",
    "    Dinv = 1 / D\n",
    "    if init == 'pca':\n",
    "        [UU,DD,_] = np.linalg.svd(x)\n",
    "        y = UU[:,:n]*DD[:n] \n",
    "    elif init == 'cmdscale':\n",
    "        from cmdscale import cmdscale\n",
    "        y,e = cmdscale(D)\n",
    "        y = y[:,:n]\n",
    "    else:\n",
    "        y = np.random.normal(0.0,1.0,[N,n])\n",
    "    one = np.ones([N,n])\n",
    "    d = cdist(y,y) + np.eye(N)\n",
    "    dinv = 1. / d\n",
    "    delta = D-d \n",
    "    E = ((delta**2)*Dinv).sum() \n",
    "\n",
    "    # Get on with it\n",
    "    for i in range(maxiter):\n",
    "\n",
    "        # Compute gradient, Hessian and search direction (note it is actually\n",
    "        # 1/4 of the gradient and Hessian, but the step size is just the ratio\n",
    "        # of the gradient and the diagonal of the Hessian so it doesn't\n",
    "        # matter).\n",
    "        delta = dinv - Dinv\n",
    "        deltaone = np.dot(delta,one)\n",
    "        g = np.dot(delta,y) - (y * deltaone)\n",
    "        dinv3 = dinv ** 3\n",
    "        y2 = y ** 2\n",
    "        H = np.dot(dinv3,y2) - deltaone - np.dot(2,y) * np.dot(dinv3,y) + y2 * np.dot(dinv3,one)\n",
    "        s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))\n",
    "        y_old    = y\n",
    "\n",
    "        # Use step-halving procedure to ensure progress is made\n",
    "        for j in range(maxhalves):\n",
    "            s_reshape = np.reshape(s, (-1,n),order='F')\n",
    "            y = y_old + s_reshape\n",
    "            d = cdist(y, y) + np.eye(N)\n",
    "            dinv = 1 / d\n",
    "            delta = D - d\n",
    "            E_new = ((delta**2)*Dinv).sum()\n",
    "            if E_new < E:\n",
    "                break\n",
    "            else:\n",
    "                s = 0.5*s\n",
    "\n",
    "        # Bomb out if too many halving steps are required\n",
    "        if j == maxhalves-1:\n",
    "            print('Warning: maxhalves exceeded. Sammon mapping may not converge...')\n",
    "\n",
    "        # Evaluate termination criterion\n",
    "        if abs((E - E_new) / E) < tolfun:\n",
    "            if display:\n",
    "                print('TolFun exceeded: Optimisation terminated')\n",
    "            break\n",
    "\n",
    "        # Report progress\n",
    "        E = E_new\n",
    "        if display > 1:\n",
    "            print('epoch = %d : E = %12.10f'% (i+1, E * scale))\n",
    "\n",
    "    if i == maxiter-1:\n",
    "        print('Warning: maxiter exceeded. Sammon mapping may not have converged...')\n",
    "\n",
    "    # Fiddle stress to match the original Sammon paper\n",
    "    E = E * scale\n",
    "    \n",
    "    return [y,E]\n",
    "\n",
    "def getList(dict):\n",
    "    list = []\n",
    "    for key in winmap.keys():\n",
    "        list.append(key)      \n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbe1ed-36d9-48f9-a133-80ece8291fc1",
   "metadata": {},
   "source": [
    "You will need to open the data_train that we saved from the SOM Step #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788d8aa-ea3a-4511-b744-b85fbb65df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#State the path where the file is located\n",
    "PATH = '/Users/research/thesis_code/SOMs/'  #This is the path where the data files are stored.\n",
    "PATH_SAVE = '/Users/research/thesis_code/SOMs_TEST/'  #This is the folder where we will save the SOMs themselves as well as the plots for each SOM.\n",
    "\n",
    "data_train = np.load('TEST2_som_data_train.npy')\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0cf77-3455-4a41-b469-02b5969dda0a",
   "metadata": {},
   "source": [
    "Define the parameters for the SOM:\n",
    "Please refer to https://github.com/JustGlowing/minisom/blob/master/minisom.py for full documentation on the functions/parameters of MiniSOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46ceda-2d6c-4a6b-810f-a6a28009541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You want to change these to the settings that you would like. \n",
    "x= 4 #columns\n",
    "y= 3 #row\n",
    "input_length = 216 #This is value is the the length of the latitude X longitude. It is the second value in the data_train.shape step. \n",
    "sigma = 2         #The sigma value must be y-1. \n",
    "learning_rate = 0.0005  #Learning Rate \n",
    "qerror_list = []\n",
    "q_win = 100000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a949f4-28c5-4ed8-b3d9-7ab7ea78f376",
   "metadata": {},
   "source": [
    "We will now generate the SOMs themselves. This is an iterative process. For this tutorial, the SOMs will be generated using a 1-Step process; however, SOMs can be made using a 2-Step process as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5caaeb-adb0-4680-a70a-de649d6f4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):   #The number of SOMs that will be generated. \n",
    "    # initialize random weights\n",
    "    era5_hourly_som1 = minisom.MiniSom(y,x, input_len = input_length, sigma = sigma, learning_rate=learning_rate, neighborhood_function='bubble', decay_function = asymptotic_decay)\n",
    "    era5_hourly_som1.random_weights_init(data_train)\n",
    "    # train som\n",
    "    era5_hourly_som1.train(data_train, num_iteration=100000,random_order=True, verbose=True)\n",
    "    q_error = era5_hourly_som1.quantization_error(data_train)\n",
    "    \n",
    "    #Add the details of the SOM settings into the name of the file so that you know what the SOM is showing.\n",
    "    with open(PATH_SAVE + '06122023_4by3_LR0.0005_sig2_SOM_som_'+str(i)+'.p', 'wb') as outfile: #this is how you save the file, the str(i) is a unique name\n",
    "        pickle.dump(era5_hourly_som1, outfile)\n",
    "    weights = era5_hourly_som1._weights\n",
    "    qerror_list += [q_error]\n",
    "    i+=1\n",
    "    if q_error < q_win:\n",
    "        q_win = q_error\n",
    "        win_weights = era5_hourly_som1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a24ad-01ea-4165-b29a-e551e7592d06",
   "metadata": {},
   "source": [
    "We will now open the remaining variables that were saved from Step #1. We will need these variables for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b8e96-1684-409b-b095-003712df6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_values = np.load('TEST_som_time_data.npy')\n",
    "mslpraw = xr.open_dataset('/Users/research/thesis_code/SOM_MSLPraw_NCEP_data.nc')\n",
    "mslp = mslpraw['mslp'].values\n",
    "mslp_SOM = mslpraw['mslp']\n",
    "lon = mslpraw['lon'].values\n",
    "lat = mslpraw['lat'].values\n",
    "nx = int((mslpraw['lat'].size))\n",
    "ny = int((mslpraw['lon'].size))\n",
    "nhours =int((mslpraw['time'].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e71f78-a67f-4cac-9837-295951e298be",
   "metadata": {},
   "source": [
    "We will begin by plotting the frequency Plots and then the Sammon Plots for each SOM made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b8dc9-507a-4a4a-897e-90b50ab0a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the SOM Columns and the Rows \n",
    "som_col = 4\n",
    "som_row = 3\n",
    "x_coor = 4\n",
    "y_coor= 3\n",
    "\n",
    "folderpath = '\\\\Users\\\\research\\\\thesis_code\\\\SOMs_TEST\\\\'  #This is where all your SOMs were saved\n",
    "\n",
    "names = ([os.path.splitext(os.path.split(x)[-1])[0] for x in glob.glob(\"\\\\Users\\\\research\\\\thesis_code\\\\SOMs_TEST\\\\06122023_4by3_LR0.0005_sig2_SOM_som_*\")]) #this might be different for you\n",
    "\n",
    "#but this is just grabbing the first few characters of my names of my file (see above how I named them, for example som_8\n",
    "\n",
    "filepaths = glob.glob(\"\\\\Users\\\\research\\\\thesis_code\\\\SOMs_TEST\\\\06122023_4by3_LR0.0005_sig2_SOM_som_*\") #this is showing the path and the given file\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f789fb-9716-4ffe-9550-b9415841b215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path, name in zip(filepaths, names):\n",
    "    with open (path, 'rb') as f:\n",
    "        file = pickle.load(f) #This is loading every single som in that location\n",
    "        frequencies = file.activation_response(data_train) #this is grabbing each freq\n",
    "        q_error = round(file.quantization_error(data_train),3) #this is grabbing every q error out to 3 decimal places\n",
    "        topo_error = round(file.topographic_error(data_train),3) #this is grabbing ever topographic error out to 3 decimal places\n",
    "        plt.figure(figsize=(6,6))\n",
    "        cs = plt.pcolormesh(frequencies, cmap='Blues')\n",
    "        plt.title(name + ' ' + 'Frequencies,' + ' ' + 'Q_error =' + ' ' f\"{q_error}\" + ' ' + 'Topo_error =' + ' ' f\"{topo_error}\", fontsize=12)\n",
    "\n",
    "        #in the title, I am plotting every q error and topo error from each som. You need to have the f\" in front and whatever variable in {}\n",
    "        #And this ' ' represents a space in the title\n",
    "        plt.colorbar(cs)\n",
    "        plt.ylim(3,0) # Change the 3 to whatever size SOM you have (this is the 2nd number)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(folderpath + 'frequencies_'+name+'.png') #I am saving the outputs as a png file in the same file path and giving it the name of each SOM\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        [y,E] = sammon(file.get_weights().reshape(som_col*som_row, input_length),2,display=1)\n",
    "\n",
    "            # Plot Sammon map nodes\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.scatter(y[:,0], y[:,1], s=20, c='black', marker='o')\n",
    "\n",
    "            # Add lines between nodes\n",
    "        mslp = np.reshape(y,(som_row,som_col,2))\n",
    "        len_x, len_y, len_z = mslp.shape\n",
    "\n",
    "        # add vertical lines\n",
    "        for i in range(len_x-1):\n",
    "            for j in range(len_y):\n",
    "                plt.plot(mslp[i:i+2,j,0],mslp[i:i+2,j,1],c='black')\n",
    "\n",
    "        # add horizontal lines\n",
    "        for i in range(len_x):\n",
    "            for j in range(len_y-1):\n",
    "                plt.plot(mslp[i,j:j+2,0],mslp[i,j:j+2,1],c='black')  \n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(name, fontsize=12)\n",
    "        plt.savefig(folderpath + 'sammonplot_'+name+'.png') #I am saving the outputs as a png file in the same file path and giving it the name of each SOM\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d166b8-e763-4065-90ad-2c0e46f9e697",
   "metadata": {},
   "source": [
    "We will now loop through and plot the MSLP Anomaly Plots for each SOM. This is how we will visualize the SOM output.\n",
    "***You will need to update the following lines in the code block below to the dimensions of YOUR SOM.***\n",
    "Lines: 7, 17,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8103d-ab02-499b-9c5c-822232b98fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path, name in zip(filepaths, names):\n",
    "    with open (path, 'rb') as f:\n",
    "        som = pickle.load(f)\n",
    "        weights = som._weights\n",
    "\n",
    "        #Need to create a new dictionary for the new data\n",
    "        keys = [i for i in product(range(3), range(4))]\n",
    "        winmap = {key: [] for key in keys}\n",
    "\n",
    "        for i, x in enumerate(data_train):\n",
    "            winmap[som.winner(x)].append(i)\n",
    "            som_keys = getList(winmap)\n",
    "        frequencies = som.activation_response(data_train)\n",
    "        datacrs = ccrs.PlateCarree()\n",
    "        \n",
    "        #You will set this to the dimensions of the SOM.\n",
    "        fig, axs = plt.subplots(nrows=3,ncols=4,\n",
    "                                subplot_kw={'projection':ccrs.LambertConformal(central_longitude=-156, central_latitude=71, standard_parallels=(30, 60))},\n",
    "                                figsize=(30, 15),facecolor='white') \n",
    "        fig.tight_layout()\n",
    "\n",
    "\n",
    "        axs=axs.flatten()\n",
    "#############################################################################################################################################################################################################\n",
    "        \n",
    "        #THIS IS VERY IMPORTANT you will multiply the \"k\" in the node = line by the largest value of the SOM so in the case of a 4x3 it will be multiplied by 4. For example,\n",
    "        #if your SOM was an 8x5 you would multiple the k by 8.\n",
    "#############################################################################################################################################################################################################\n",
    "        \n",
    "        for k in range(weights.shape[0]):\n",
    "            for i in range(weights.shape[1]):\n",
    "                #node = (k,i)\n",
    "                node=(k*4)+i\n",
    "                SOM_mslp = weights[k,i,:].reshape(nx,ny)\n",
    "                #levs = np.arange(-10, 10, 2)\n",
    "                lev_start = -12\n",
    "                lev_step= 2\n",
    "                levs = (np.arange(lev_start-(lev_step/2), np.abs(lev_start)+(lev_step/2)+lev_step,lev_step))\n",
    "                cs2=axs[(k*4)+i].contourf(lon, lat, SOM_mslp,\n",
    "                                  transform = ccrs.PlateCarree(),\n",
    "                                  cmap='coolwarm', levels = levs,extend='both')\n",
    "                axs[(k*4)+i].set_extent([-131.7, -180, 73.48, 62.9], ccrs.PlateCarree() )\n",
    "\n",
    "                axs[(k*4)+i].coastlines()\n",
    "                axs[(k*4)+i].add_feature(cfeature.BORDERS) \n",
    "                axs[(k*4)+i].scatter(-156.36,71.19, c='yellow',marker= 'o',s=120, linewidth=2,edgecolors= \"black\" ,zorder= 4,transform=datacrs)\n",
    "\n",
    "\n",
    "                # Title each subplot \n",
    "                axs[(k*4)+i].set_title('Node:'+str(node), fontsize=18)\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "                fig.subplots_adjust(bottom=0.25, top=0.9, left=0.05, right=0.6,\n",
    "                            wspace=0.05, hspace=0.25)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.08, 0.2, 0.5, 0.02])\n",
    "        cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = np.arange(lev_start, np.abs(lev_start)+lev_step, lev_step*2),orientation='horizontal')\n",
    "\n",
    "        cbar.set_label('MSLP (hPa)', fontsize=22)\n",
    "\n",
    "        plt.suptitle('SOM Nodes: MSLP Anomalies (hPa). '+name+'', x= 0.33 ,fontsize=22)   \n",
    "        plt.savefig(folderpath + 'anomalyplot_'+name+'.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1c3bf-b102-4d94-8edf-01bb3aaf2055",
   "metadata": {},
   "source": [
    "The End!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
